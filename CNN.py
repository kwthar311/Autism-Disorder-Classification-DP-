# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LeInQNMWeb3w59XXdsVE6ka7b9RSzsfF
"""

from keras.preprocessing.image import ImageDataGenerator

# create a new generator
imagegen = ImageDataGenerator()
# load train data
train = imagegen.flow_from_directory(train_path, class_mode="categorical", shuffle=False, batch_size=100, target_size=(224, 224))
# load val data
val = imagegen.flow_from_directory(test_path, class_mode="categorical", shuffle=False, batch_size=100, target_size=(224, 224))
# load val data

from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout

# build a sequential model
model = Sequential()
model.add(InputLayer(input_shape=(224, 224, 3)))

# 1st conv block
model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))
model.add(MaxPool2D(pool_size=(2, 2), padding='same'))
# 2nd conv block
model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))
model.add(MaxPool2D(pool_size=(2, 2), padding='same'))
model.add(BatchNormalization())
# 3rd conv block
model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))
model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))
model.add(BatchNormalization())
# ANN block
model.add(Flatten())
model.add(Dense(units=100, activation='relu'))
model.add(Dense(units=100, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(units=2, activation='softmax'))

# compile model
opt =keras.optimizers.Adam(learning_rate=0.0001)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
# fit on data for 30 epochs
model.fit_generator(train, epochs=40, validation_data=val)
model.save("alexnet2.h5")

import os
from keras.preprocessing import image
import matplotlib.pyplot as plt
from keras.models import load_model
import pandas as pd

my_img =[]
labels =[]
path =test_path
for i in os.listdir(path):
  my_img.append(i)
  img=image.load_img(path +'//'+i)
  x =image.array_to_img(img)
  x =np.expand_dims(img,axis=0)
  sav= load_model("alexnet2.h5")
  out =sav.predict(x)
  print(out)
  if out[0][1]> out[0][0]:
    print("non_autistic")
    label = 0
    labels.append(label)
  else:
    print("autistic")
    label = 1
    labels.append(label)
submit =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Submit.csv')
submit['Image'] = my_img
print(submit['Image'])
submit['Label'] = labels
submit.to_csv("submit1.csv",index=False)
#print("Done!")

"""import keras
from keras.models import sequential
from keras.layers import Dense,Activation,Dropout,Flatten,Conv2D,MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
import numpy as np

image_shape =(224,224,3)

train_path ='/content/drive/MyDrive/Colab Notebooks/train/train'
test_path = '/content/drive/MyDrive/Colab Notebooks/test/test'

"""